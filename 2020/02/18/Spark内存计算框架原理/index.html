<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="spark内存计算框架1. RDD的依赖关系  RDD和它依赖的父RDD的关系有两种不同的类型">
<meta name="keywords" content="Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark内存计算框架原理">
<meta property="og:url" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/index.html">
<meta property="og:site_name" content="一只鱼的博客">
<meta property="og:description" content="spark内存计算框架1. RDD的依赖关系  RDD和它依赖的父RDD的关系有两种不同的类型">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/rdd-dependencies.png">
<meta property="og:image" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/1569036662039.png">
<meta property="og:image" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/1569036703460.png">
<meta property="og:image" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/1569037915592.png">
<meta property="og:image" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/1569045749546.png">
<meta property="og:image" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/1569047954944.png">
<meta property="og:image" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/%E5%88%92%E5%88%86stage.png">
<meta property="og:image" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/stage.png">
<meta property="og:image" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/spark%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6.png">
<meta property="og:image" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/spark.png">
<meta property="og:image" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/job-scheduler-running.png">
<meta property="og:updated_time" content="2020-02-20T05:05:06.348Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark内存计算框架原理">
<meta name="twitter:description" content="spark内存计算框架1. RDD的依赖关系  RDD和它依赖的父RDD的关系有两种不同的类型">
<meta name="twitter:image" content="http://yoursite.com/2020/02/18/Spark内存计算框架原理/rdd-dependencies.png">
  <link rel="canonical" href="http://yoursite.com/2020/02/18/Spark内存计算框架原理/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Spark内存计算框架原理 | 一只鱼的博客</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">一只鱼的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">七秒钟的记忆多一秒</p>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    
      
      
        
      
        
      
        
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-question-circle"></i>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    
      
      
        
      
        
      
        
      
    

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    
      
      
        
      
        
      
        
          
        
      
    

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-question-circle"></i>标签<span class="badge">44</span></a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    
      
      
        
      
        
          
        
      
        
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-question-circle"></i>分类<span class="badge">10</span></a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    
      
      
        
          
        
      
        
      
        
      
    

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-question-circle"></i>归档<span class="badge">67</span></a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-schedule">
      
    
      
      
        
      
        
      
        
      
    

    <a href="/schedule/" rel="section"><i class="fa fa-fw fa-calendar"></i>日程表</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-sitemap">
      
    
      
      
        
      
        
      
        
      
    

    <a href="/sitemap.xml" rel="section"><i class="fa fa-fw fa-sitemap"></i>站点地图</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-commonweal">
      
    
      
      
        
      
        
      
        
      
    

    <a href="/404/" rel="section"><i class="fa fa-fw fa-heartbeat"></i>公益 404</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/18/Spark内存计算框架原理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小鱼儿">
      <meta itemprop="description" content="肩膀有点痒，可能在长小翅膀">
      <meta itemprop="image" content="/images/fish.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只鱼的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">Spark内存计算框架原理

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2020-02-18 15:17:03" itemprop="dateCreated datePublished" datetime="2020-02-18T15:17:03+08:00">2020-02-18</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-20 13:05:06" itemprop="dateModified" datetime="2020-02-20T13:05:06+08:00">2020-02-20</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/大数据开发/" itemprop="url" rel="index"><span itemprop="name">大数据开发</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="spark内存计算框架"><a href="#spark内存计算框架" class="headerlink" title="spark内存计算框架"></a>spark内存计算框架</h1><h3 id="1-RDD的依赖关系"><a href="#1-RDD的依赖关系" class="headerlink" title="1. RDD的依赖关系"></a>1. RDD的依赖关系</h3><p><img src="/2020/02/18/Spark内存计算框架原理/rdd-dependencies.png" alt></p>
<ul>
<li>RDD和它依赖的父RDD的关系有两种不同的类型</li>
</ul>
<a id="more"></a>

<ul>
<li><p>窄依赖（narrow dependency）和宽依赖（wide dependency）</p>
<ul>
<li><p>窄依赖</p>
<ul>
<li><p>窄依赖指的是每一个父RDD的Partition最多被子RDD的一个Partition使用</p>
<ul>
<li>总结：窄依赖我们形象的比喻为独生子女</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">哪些算子操作是窄依赖：</span><br><span class="line">	map/flatMap/filter/union等等</span><br><span class="line">	</span><br><span class="line">	所有的窄依赖不会产生shuffle</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>宽依赖</p>
<ul>
<li><p>宽依赖指的是多个子RDD的Partition会依赖同一个父RDD的Partition</p>
<ul>
<li>总结：宽依赖我们形象的比喻为超生 </li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">哪些算子操作是宽依赖：</span><br><span class="line">	reduceByKey/sortByKey/groupBy/groupByKey/join等等</span><br><span class="line">	</span><br><span class="line">	所有的宽依赖会产生shuffle</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>补充说明</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">由上图可知，join分为宽依赖和窄依赖，如果RDD有相同的partitioner，那么将不会引起shuffle，这种join是窄依赖，反之就是宽依赖</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h3 id="2-lineage（血统）"><a href="#2-lineage（血统）" class="headerlink" title="2. lineage（血统）"></a>2. lineage（血统）</h3><ul>
<li>RDD只支持粗粒度转换<ul>
<li>即只记录单个块上执行的单个操作。</li>
</ul>
</li>
<li>将创建RDD的一系列Lineage（即血统）记录下来，以便恢复丢失的分区</li>
<li>RDD的Lineage会记录RDD的元数据信息和转换行为，lineage保存了RDD的依赖关系，当该RDD的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。</li>
</ul>
<h3 id="3-RDD的缓存机制（★★★★★"><a href="#3-RDD的缓存机制（★★★★★" class="headerlink" title="3. RDD的缓存机制（★★★★★)"></a>3. RDD的缓存机制（★★★★★)</h3><h4 id="3-1-什么是rdd的缓存"><a href="#3-1-什么是rdd的缓存" class="headerlink" title="3.1 什么是rdd的缓存"></a>3.1 什么是rdd的缓存</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">可以把一个rdd的数据缓存起来，后续有其他的job需要用到该rdd的结果数据，可以直接从缓存中获取得到，避免了重复计算。缓存是加快后续对该数据的访问操作。</span><br></pre></td></tr></table></figure>

<h4 id="3-2-如何对rdd设置缓存"><a href="#3-2-如何对rdd设置缓存" class="headerlink" title="3.2 如何对rdd设置缓存"></a>3.2 如何对rdd设置缓存</h4><ul>
<li>RDD通过persist方法或cache方法可以将前面的计算结果缓存。<ul>
<li>但是并不是这两个方法被调用时立即缓存，而是==触发后面的action==时，该RDD将会被缓存在计算节点的内存中，并供后面重用。</li>
</ul>
</li>
</ul>
<p><img src="/2020/02/18/Spark内存计算框架原理/1569036662039.png" alt></p>
<ul>
<li>通过查看源码发现cache最终也是调用了persist方法，默认的存储级别都是仅在内存存储一份，Spark的存储级别还有好多种，存储级别在object StorageLevel中定义的。</li>
</ul>
<p><img src="/2020/02/18/Spark内存计算框架原理/1569036703460.png" alt></p>
<ul>
<li>使用演示</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1=sc.textFile(<span class="string">"/words.txt"</span>)</span><br><span class="line"><span class="keyword">val</span> rdd2=rdd1.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"><span class="keyword">val</span> rdd3=rdd2.cache</span><br><span class="line">rdd3.collect</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> rdd4=rdd3.map((_,<span class="number">1</span>))</span><br><span class="line"><span class="keyword">val</span> rdd5=rdd4.persist(缓存级别)</span><br><span class="line">rdd5.collect</span><br></pre></td></tr></table></figure>

<h4 id="3-3-cache和persist区别"><a href="#3-3-cache和persist区别" class="headerlink" title="3.3 cache和persist区别"></a>3.3 cache和persist区别</h4><ul>
<li><p>面试经常被问到(★★★★★)</p>
<ul>
<li>例如<ul>
<li>简述下如何对RDD设置缓存，以及它们的区别是什么？</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">	对RDD设置缓存成可以调用rdd的2个方法： 一个是cache，一个是persist</span><br><span class="line">调用上面2个方法都可以对rdd的数据设置缓存，但不是立即就触发缓存执行，后面需要有action，才会触发缓存的执行。</span><br><span class="line"></span><br><span class="line">cache方法和persist方法区别：</span><br><span class="line">    cache:   默认是把数据缓存在内存中，其本质就是调用persist方法；</span><br><span class="line">    persist：可以把数据缓存在内存或者是磁盘，有丰富的缓存级别，这些缓存级别都被定义在StorageLevel这个object中。</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="3-4-什么时候设置缓存"><a href="#3-4-什么时候设置缓存" class="headerlink" title="3.4 什么时候设置缓存"></a>3.4 什么时候设置缓存</h4><ul>
<li>1、某个rdd的数据后期被使用了多次</li>
</ul>
<p><img src="/2020/02/18/Spark内存计算框架原理/1569037915592.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">如上图所示的计算逻辑： </span><br><span class="line">（1）当第一次使用rdd2做相应的算子操作得到rdd3的时候，就会从rdd1开始计算，先读取HDFS上的文件，然后对rdd1 做对应的算子操作得到rdd2,再由rdd2计算之后得到rdd3。同样为了计算得到rdd4，前面的逻辑会被重新计算。</span><br><span class="line"></span><br><span class="line">（2）默认情况下多次对一个rdd执行算子操作， rdd都会对这个rdd及之前的父rdd全部重新计算一次。 这种情况在实际开发代码的时候会经常遇到，但是我们一定要避免一个rdd重复计算多次，否则会导致性能急剧降低。   </span><br><span class="line"></span><br><span class="line">总结：</span><br><span class="line">可以把多次使用到的rdd，也就是公共rdd进行持久化，避免后续需要，再次重新计算，提升效率。</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/18/Spark内存计算框架原理/1569045749546.png" alt></p>
<ul>
<li>2、为了获取得到一个rdd的结果数据，经过了大量的算子操作或者是计算逻辑比较复杂<ul>
<li>总之某个rdd的数据来之不易</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val rdd2=rdd1.flatMap(函数).map(函数).reduceByKey(函数).xxx.xxx.xxx.xxx.xxx</span><br></pre></td></tr></table></figure>

<h4 id="3-5-清除缓存数据"><a href="#3-5-清除缓存数据" class="headerlink" title="3.5  清除缓存数据"></a>3.5  清除缓存数据</h4><ul>
<li><p>1、自动清除</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一个application应用程序结束之后，对应的缓存数据也就自动清除</span><br></pre></td></tr></table></figure>
</li>
<li><p>2、手动清除</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">调用rdd的unpersist方法</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="4-RDD的checkpoint机制（★★★★★"><a href="#4-RDD的checkpoint机制（★★★★★" class="headerlink" title="4. RDD的checkpoint机制（★★★★★)"></a>4. RDD的checkpoint机制（★★★★★)</h3><h4 id="4-1-checkpoint概念"><a href="#4-1-checkpoint概念" class="headerlink" title="4.1 checkpoint概念"></a>4.1 checkpoint概念</h4><ul>
<li><p>我们可以对rdd的数据进行缓存，保存在内存或者是磁盘中。</p>
<ul>
<li><p>后续就可以直接从内存或者磁盘中获取得到，但是它们不是特别安全。</p>
</li>
<li><p><strong>cache</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">它是直接把数据保存在内存中，后续操作起来速度比较快，直接从内存中获取得到。但这种方式很不安全，由于服务器挂掉或者是进程终止，会导致数据的丢失。</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>persist</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">它可以把数据保存在本地磁盘中，后续可以从磁盘中获取得到该数据，但它也不是特别安全，由于系统管理员一些误操作删除了，或者是磁盘损坏，也有可能导致数据的丢失。</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>checkpoint</strong>（检查点）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">它是提供了一种相对而言更加可靠的数据持久化方式。它是把数据保存在分布式文件系统，</span><br><span class="line">比如HDFS上。这里就是利用了HDFS高可用性，高容错性（多副本）来最大程度保证数据的安全性。</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="4-2-如何设置checkpoint"><a href="#4-2-如何设置checkpoint" class="headerlink" title="4.2 如何设置checkpoint"></a>4.2 如何设置checkpoint</h4><ul>
<li><p>1、在hdfs上设置一个checkpoint目录</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.setCheckpointDir(<span class="string">"hdfs://node01:8020/checkpoint"</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>2、对需要做checkpoint操作的rdd调用checkpoint方法</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1=sc.textFile(<span class="string">"/words.txt"</span>)</span><br><span class="line">rdd1.checkpoint</span><br><span class="line"><span class="keyword">val</span> rdd2=rdd1.flatMap(_.split(<span class="string">" "</span>))</span><br></pre></td></tr></table></figure>
</li>
<li><p>3、最后需要有一个action操作去触发任务的运行</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd2.collect</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="4-3-cache、persist、checkpoint三者区别"><a href="#4-3-cache、persist、checkpoint三者区别" class="headerlink" title="4.3 cache、persist、checkpoint三者区别"></a>4.3 cache、persist、checkpoint三者区别</h4><ul>
<li>cache和persist<ul>
<li>cache默认数据缓存在内存中</li>
<li>persist可以把数据保存在内存或者磁盘中</li>
<li>后续要触发 cache 和 persist 持久化操作，需要有一个action操作</li>
<li>它不会开启其他新的任务，一个action操作就对应一个job </li>
<li>它不会改变rdd的依赖关系，程序运行完成后对应的缓存数据就自动消失</li>
</ul>
</li>
<li>checkpoint<ul>
<li>可以把数据持久化写入到hdfs上</li>
<li>后续要触发checkpoint持久化操作，需要有一个action操作，后续会开启新的job执行checkpoint操作</li>
<li>它会改变rdd的依赖关系，后续数据丢失了不能够在通过血统进行数据的恢复。</li>
<li>程序运行完成后对应的checkpoint数据就不会消失</li>
</ul>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sc.setCheckpointDir(<span class="string">"/checkpoint"</span>)</span><br><span class="line"><span class="keyword">val</span> rdd1=sc.textFile(<span class="string">"/words.txt"</span>)</span><br><span class="line"><span class="keyword">val</span> rdd2=rdd1.cache</span><br><span class="line">rdd2.checkpoint</span><br><span class="line"><span class="keyword">val</span> rdd3=rdd2.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">rdd3.collect</span><br><span class="line"></span><br><span class="line">checkpoint操作要执行需要有一个action操作，一个action操作对应后续的一个job。该job执行完成之后，它会再次单独开启另外一个job来执行 rdd1.checkpoint操作。</span><br><span class="line"></span><br><span class="line">对checkpoint在使用的时候进行优化，在调用checkpoint操作之前，可以先来做一个cache操作，缓存对应rdd的结果数据，后续就可以直接从cache中获取到rdd的数据写入到指定checkpoint目录中</span><br></pre></td></tr></table></figure>

<h3 id="5-DAG有向无环图生成"><a href="#5-DAG有向无环图生成" class="headerlink" title="5. DAG有向无环图生成"></a>5. DAG有向无环图生成</h3><h4 id="5-1-DAG是什么"><a href="#5-1-DAG是什么" class="headerlink" title="5.1 DAG是什么"></a>5.1 DAG是什么</h4><ul>
<li>DAG(Directed Acyclic Graph) 叫做有向无环图（有方向,无闭环,代表着数据的流向），原始的RDD通过一系列的转换就形成了DAG。</li>
<li>下图是基于单词统计逻辑得到的DAG有向无环图</li>
</ul>
<p><img src="/2020/02/18/Spark内存计算框架原理/1569047954944.png" alt></p>
<h3 id="6-DAG划分stage（★★★★★"><a href="#6-DAG划分stage（★★★★★" class="headerlink" title="6. DAG划分stage（★★★★★)"></a>6. DAG划分stage（★★★★★)</h3><h4 id="6-1-stage是什么"><a href="#6-1-stage是什么" class="headerlink" title="6.1 stage是什么"></a>6.1 stage是什么</h4><ul>
<li>一个Job会被拆分为多组Task，每组任务被称为一个stage</li>
<li>stage表示不同的调度阶段，一个spark job会对应产生很多个stage<ul>
<li>stage类型一共有2种<ul>
<li>ShuffleMapStage<ul>
<li>最后一个shuffle之前的所有变换的Stage叫ShuffleMapStage<ul>
<li>它对应的task是shuffleMapTask</li>
</ul>
</li>
</ul>
</li>
<li>ResultStage<ul>
<li>最后一个shuffle之后操作的Stage叫ResultStage，它是最后一个Stage。<ul>
<li>它对应的task是ResultTask</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="6-2-为什么要划分stage"><a href="#6-2-为什么要划分stage" class="headerlink" title="6.2 为什么要划分stage"></a>6.2 为什么要划分stage</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">根据RDD之间依赖关系的不同将DAG划分成不同的Stage(调度阶段)</span><br><span class="line">对于窄依赖，partition的转换处理在一个Stage中完成计算</span><br><span class="line">对于宽依赖，由于有Shuffle的存在，只能在parent RDD处理完成后，才能开始接下来的计算，</span><br><span class="line"></span><br><span class="line">由于划分完stage之后，在同一个stage中只有窄依赖，没有宽依赖，可以实现流水线计算，</span><br><span class="line">stage中的每一个分区对应一个task，在同一个stage中就有很多可以并行运行的task。</span><br></pre></td></tr></table></figure>

<h4 id="6-3-如何划分stage"><a href="#6-3-如何划分stage" class="headerlink" title="6.3 如何划分stage"></a>6.3 如何划分stage</h4><ul>
<li>划分stage的依据就是宽依赖</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(1) 首先根据rdd的算子操作顺序生成DAG有向无环图，接下里从最后一个rdd往前推，创建一个新的stage，把该rdd加入到该stage中，它是最后一个stage。</span><br><span class="line"></span><br><span class="line">(2) 在往前推的过程中运行遇到了窄依赖就把该rdd加入到本stage中，如果遇到了宽依赖，就从宽依赖切开，那么最后一个stage也就结束了。</span><br><span class="line"></span><br><span class="line">(3) 重新创建一个新的stage，按照第二个步骤继续往前推，一直到最开始的rdd，整个划分stage也就结束了</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/18/Spark内存计算框架原理/%E5%88%92%E5%88%86stage.png" alt></p>
<h4 id="6-4-stage与stage之间的关系"><a href="#6-4-stage与stage之间的关系" class="headerlink" title="6.4 stage与stage之间的关系"></a>6.4 stage与stage之间的关系</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">	划分完stage之后，每一个stage中有很多可以并行运行的task，后期把每一个stage中的task封装在一个taskSet集合中，最后把一个一个的taskSet集合提交到worker节点上的executor进程中运行。</span><br><span class="line"></span><br><span class="line">rdd与rdd之间存在依赖关系，stage与stage之前也存在依赖关系，前面stage中的task先运行，运行完成了再运行后面stage中的task，也就是说后面stage中的task输入数据是前面stage中task的输出结果数据。</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/18/Spark内存计算框架原理/stage.png" alt></p>
<h3 id="7、spark的任务调度"><a href="#7、spark的任务调度" class="headerlink" title="7、spark的任务调度"></a>7、spark的任务调度</h3><p><img src="/2020/02/18/Spark内存计算框架原理/spark%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(1) Driver端运行客户端的main方法，构建SparkContext对象，在SparkContext对象内部依次构建DAGScheduler和TaskScheduler</span><br><span class="line"></span><br><span class="line">(2) 按照rdd的一系列操作顺序，来生成DAG有向无环图</span><br><span class="line"></span><br><span class="line">(3) DAGScheduler拿到DAG有向无环图之后，按照宽依赖进行stage的划分。每一个stage内部有很多可以并行运行的task，最后封装在一个一个的taskSet集合中，然后把taskSet发送给TaskScheduler</span><br><span class="line"></span><br><span class="line">(4) TaskScheduler得到taskSet集合之后，依次遍历取出每一个task提交到worker节点上的executor进程中运行。</span><br><span class="line"></span><br><span class="line">(5) 所有task运行完成，整个任务也就结束了</span><br></pre></td></tr></table></figure>

<h3 id="8、spark的运行架构"><a href="#8、spark的运行架构" class="headerlink" title="8、spark的运行架构"></a>8、spark的运行架构</h3><p><img src="/2020/02/18/Spark内存计算框架原理/spark.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">(1) Driver端向资源管理器Master发送注册和申请计算资源的请求</span><br><span class="line"></span><br><span class="line">(2) Master通知对应的worker节点启动executor进程(计算资源)</span><br><span class="line"></span><br><span class="line">(3) executor进程向Driver端发送注册并且申请task请求</span><br><span class="line"></span><br><span class="line">(4) Driver端运行客户端的main方法，构建SparkContext对象，在SparkContext对象内部依次构建DAGScheduler和TaskScheduler</span><br><span class="line"></span><br><span class="line">(5) 按照客户端代码洪rdd的一系列操作顺序，生成DAG有向无环图</span><br><span class="line"></span><br><span class="line">(6) DAGScheduler拿到DAG有向无环图之后，按照宽依赖进行stage的划分。每一个stage内部有很多可以并行运行的task，最后封装在一个一个的taskSet集合中，然后把taskSet发送给TaskScheduler</span><br><span class="line"></span><br><span class="line">(7) TaskScheduler得到taskSet集合之后，依次遍历取出每一个task提交到worker节点上的executor进程中运行</span><br><span class="line"></span><br><span class="line">(8) 所有task运行完成，Driver端向Master发送注销请求，Master通知Worker关闭executor进程，Worker上的计算资源得到释放，最后整个任务也就结束了。</span><br></pre></td></tr></table></figure>

<h3 id="9、基于wordcount程序剖析spark任务的提交、划分、调度流程（★★★★★"><a href="#9、基于wordcount程序剖析spark任务的提交、划分、调度流程（★★★★★" class="headerlink" title="9、基于wordcount程序剖析spark任务的提交、划分、调度流程（★★★★★)"></a>9、基于wordcount程序剖析spark任务的提交、划分、调度流程（★★★★★)</h3><p><img src="/2020/02/18/Spark内存计算框架原理/job-scheduler-running.png" alt></p>
<h2 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h2><ul>
<li>1、rdd的依赖关系<ul>
<li>宽依赖</li>
<li>窄依赖</li>
</ul>
</li>
<li>2、rdd的缓存机制（★★★★★)  <ul>
<li>cache</li>
<li>persist</li>
</ul>
</li>
<li>3、checkpoint机制（★★★★★)  </li>
<li>4、DAG有向无环图是什么</li>
<li>5、如何划分stage（★★★★★)  </li>
<li>6、spark任务的提交、划分、调度流程（★★★★★)  </li>
</ul>

    </div>

    
    
    
        
      
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>小鱼儿</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/2020/02/18/Spark内存计算框架原理/" title="Spark内存计算框架原理">http://yoursite.com/2020/02/18/Spark内存计算框架原理/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-Hans" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>
</div>

      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/Spark/" rel="tag"># Spark</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2020/02/17/Hive实战/" rel="next" title="Hive实战">
                  <i class="fa fa-chevron-left"></i> Hive实战
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2020/02/25/hive调优/" rel="prev" title="hive调优">
                  hive调优 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#spark内存计算框架"><span class="nav-number">1.</span> <span class="nav-text">spark内存计算框架</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-RDD的依赖关系"><span class="nav-number">1.0.1.</span> <span class="nav-text">1. RDD的依赖关系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-lineage（血统）"><span class="nav-number">1.0.2.</span> <span class="nav-text">2. lineage（血统）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-RDD的缓存机制（★★★★★"><span class="nav-number">1.0.3.</span> <span class="nav-text">3. RDD的缓存机制（★★★★★)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-什么是rdd的缓存"><span class="nav-number">1.0.3.1.</span> <span class="nav-text">3.1 什么是rdd的缓存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-如何对rdd设置缓存"><span class="nav-number">1.0.3.2.</span> <span class="nav-text">3.2 如何对rdd设置缓存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-cache和persist区别"><span class="nav-number">1.0.3.3.</span> <span class="nav-text">3.3 cache和persist区别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4-什么时候设置缓存"><span class="nav-number">1.0.3.4.</span> <span class="nav-text">3.4 什么时候设置缓存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-5-清除缓存数据"><span class="nav-number">1.0.3.5.</span> <span class="nav-text">3.5  清除缓存数据</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-RDD的checkpoint机制（★★★★★"><span class="nav-number">1.0.4.</span> <span class="nav-text">4. RDD的checkpoint机制（★★★★★)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-checkpoint概念"><span class="nav-number">1.0.4.1.</span> <span class="nav-text">4.1 checkpoint概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-如何设置checkpoint"><span class="nav-number">1.0.4.2.</span> <span class="nav-text">4.2 如何设置checkpoint</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-cache、persist、checkpoint三者区别"><span class="nav-number">1.0.4.3.</span> <span class="nav-text">4.3 cache、persist、checkpoint三者区别</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-DAG有向无环图生成"><span class="nav-number">1.0.5.</span> <span class="nav-text">5. DAG有向无环图生成</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-DAG是什么"><span class="nav-number">1.0.5.1.</span> <span class="nav-text">5.1 DAG是什么</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-DAG划分stage（★★★★★"><span class="nav-number">1.0.6.</span> <span class="nav-text">6. DAG划分stage（★★★★★)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-stage是什么"><span class="nav-number">1.0.6.1.</span> <span class="nav-text">6.1 stage是什么</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-为什么要划分stage"><span class="nav-number">1.0.6.2.</span> <span class="nav-text">6.2 为什么要划分stage</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-如何划分stage"><span class="nav-number">1.0.6.3.</span> <span class="nav-text">6.3 如何划分stage</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-4-stage与stage之间的关系"><span class="nav-number">1.0.6.4.</span> <span class="nav-text">6.4 stage与stage之间的关系</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7、spark的任务调度"><span class="nav-number">1.0.7.</span> <span class="nav-text">7、spark的任务调度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8、spark的运行架构"><span class="nav-number">1.0.8.</span> <span class="nav-text">8、spark的运行架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9、基于wordcount程序剖析spark任务的提交、划分、调度流程（★★★★★"><span class="nav-number">1.0.9.</span> <span class="nav-text">9、基于wordcount程序剖析spark任务的提交、划分、调度流程（★★★★★)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#六、总结"><span class="nav-number">1.1.</span> <span class="nav-text">六、总结</span></a></li></ol></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/fish.png"
      alt="小鱼儿">
  <p class="site-author-name" itemprop="name">小鱼儿</p>
  <div class="site-description" itemprop="description">肩膀有点痒，可能在长小翅膀</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">67</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    
  
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-Hans" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">小鱼儿</span>
</div>

        












        
      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/pisces.js?v=7.4.1"></script>

<script src="/js/next-boot.js?v=7.4.1"></script>



  





















  

  

  

</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>

