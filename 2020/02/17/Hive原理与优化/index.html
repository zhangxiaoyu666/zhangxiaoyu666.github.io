<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="0.准备安装好对应版本的hadoop集群，并启动hadoop的HDFS以及YARN服务 1. 数据仓库1.1 数据仓库的基本概念 数据仓库的英文名称为Data Warehouse，可简写为DW或DWH。">
<meta name="keywords" content="Hive">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive原理与优化">
<meta property="og:url" content="http://yoursite.com/2020/02/17/Hive原理与优化/index.html">
<meta property="og:site_name" content="一只鱼的博客">
<meta property="og:description" content="0.准备安装好对应版本的hadoop集群，并启动hadoop的HDFS以及YARN服务 1. 数据仓库1.1 数据仓库的基本概念 数据仓库的英文名称为Data Warehouse，可简写为DW或DWH。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/Snipaste_2019-07-10_23-23-31.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/1581912499438.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AC%AC%E5%9B%9B%E6%9C%9F/8_Hive%E4%B8%8EHBase%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E6%88%98/1213_hive%E8%AF%BE%E5%89%8D%E9%A2%84%E4%B9%A0%E8%AF%BE%E4%BB%B6/assets/2018040319335283.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/2019-07-11_11-08-35.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/hive1.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/Image201912101741.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/Image201912101745.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/Image201912101749.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/Image201912101754.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/Image201912101938.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/2019-07-12_14-33-00.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/2019-07-12_14-51-53.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/2019-07-15_11-35-37.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AC%AC%E5%9B%9B%E6%9C%9F/8_Hive%E4%B8%8EHBase%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E6%88%98/1213_hive%E8%AF%BE%E5%89%8D%E9%A2%84%E4%B9%A0%E8%AF%BE%E4%BB%B6/assets/Image201912111127.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AC%AC%E5%9B%9B%E6%9C%9F/8_Hive%E4%B8%8EHBase%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E6%88%98/1213_hive%E8%AF%BE%E5%89%8D%E9%A2%84%E4%B9%A0%E8%AF%BE%E4%BB%B6/assets/Image201912111128.png">
<meta property="og:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AC%AC%E5%9B%9B%E6%9C%9F/8_Hive%E4%B8%8EHBase%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E6%88%98/1213_hive%E8%AF%BE%E5%89%8D%E9%A2%84%E4%B9%A0%E8%AF%BE%E4%BB%B6/assets/hive%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8.png">
<meta property="og:updated_time" content="2020-02-17T07:12:24.855Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hive原理与优化">
<meta name="twitter:description" content="0.准备安装好对应版本的hadoop集群，并启动hadoop的HDFS以及YARN服务 1. 数据仓库1.1 数据仓库的基本概念 数据仓库的英文名称为Data Warehouse，可简写为DW或DWH。">
<meta name="twitter:image" content="http://yoursite.com/2020/02/17/Hive原理与优化/Snipaste_2019-07-10_23-23-31.png">
  <link rel="canonical" href="http://yoursite.com/2020/02/17/Hive原理与优化/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Hive原理与优化 | 一只鱼的博客</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">一只鱼的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">七秒钟的记忆多一秒</p>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    
      
      
        
      
        
      
        
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-question-circle"></i>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    
      
      
        
      
        
      
        
      
    

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    
      
      
        
      
        
      
        
          
        
      
    

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-question-circle"></i>标签<span class="badge">43</span></a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    
      
      
        
      
        
          
        
      
        
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-question-circle"></i>分类<span class="badge">10</span></a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    
      
      
        
          
        
      
        
      
        
      
    

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-question-circle"></i>归档<span class="badge">52</span></a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-schedule">
      
    
      
      
        
      
        
      
        
      
    

    <a href="/schedule/" rel="section"><i class="fa fa-fw fa-calendar"></i>日程表</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-sitemap">
      
    
      
      
        
      
        
      
        
      
    

    <a href="/sitemap.xml" rel="section"><i class="fa fa-fw fa-sitemap"></i>站点地图</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-commonweal">
      
    
      
      
        
      
        
      
        
      
    

    <a href="/404/" rel="section"><i class="fa fa-fw fa-heartbeat"></i>公益 404</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/17/Hive原理与优化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小鱼儿">
      <meta itemprop="description" content="肩膀有点痒，可能在长小翅膀">
      <meta itemprop="image" content="/images/fish.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只鱼的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">Hive原理与优化

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2020-02-17 11:52:09 / 修改时间：15:12:24" itemprop="dateCreated datePublished" datetime="2020-02-17T11:52:09+08:00">2020-02-17</time>
            </span>
          
            

            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/大数据开发/" itemprop="url" rel="index"><span itemprop="name">大数据开发</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="0-准备"><a href="#0-准备" class="headerlink" title="0.准备"></a>0.准备</h3><p>安装好对应版本的hadoop集群，并启动hadoop的HDFS以及YARN服务</p>
<h3 id="1-数据仓库"><a href="#1-数据仓库" class="headerlink" title="1. 数据仓库"></a>1. 数据仓库</h3><h4 id="1-1-数据仓库的基本概念"><a href="#1-1-数据仓库的基本概念" class="headerlink" title="1.1 数据仓库的基本概念"></a>1.1 数据仓库的基本概念</h4><ul>
<li>数据仓库的英文名称为Data Warehouse，可简写为DW或DWH。</li>
</ul>
<a id="more"></a>

<ul>
<li>数据仓库的目的是构建<strong>面向分析</strong>的集成化数据环境，为企业提供决策支持（Decision Support）。它出于分析性报告和决策支持的目的而创建。</li>
<li>数据仓库本身并不“生产”任何数据，同时自身也不需要“消费”任何的数据，数据来源于外部，并且开放给外部应用，这也是为什么叫“仓库”，而不叫“工厂”的原因。</li>
</ul>
<h4 id="1-2-数据仓库的主要特征"><a href="#1-2-数据仓库的主要特征" class="headerlink" title="1.2 数据仓库的主要特征"></a>1.2 数据仓库的主要特征</h4><p>数据仓库是</p>
<ul>
<li>面向主题的（Subject-Oriented）：一般是有一个特定的目的构建一个数据仓库</li>
<li>集成的（Integrated）：将所有用到的数据，集合到一起</li>
<li>非易失的（Non-Volatile）：数据放到数据仓库中，历史数据一般不会改变（数仓用于记录已经发生的事实的数据）</li>
<li>时变的（Time-Variant ）：分析工具可能会发生改变</li>
</ul>
<p>数据集合，用以支持管理决策。</p>
<h4 id="1-3-数据仓库与数据库区别"><a href="#1-3-数据仓库与数据库区别" class="headerlink" title="1.3 数据仓库与数据库区别"></a>1.3 数据仓库与数据库区别</h4><ul>
<li>数据库与数据仓库的区别实际讲的是OLTP 与 OLAP 的区别。 </li>
<li>操作型处理，叫联机事务处理 OLTP（On-Line Transaction Processing），也可以称面向交易的处理系统，它是针对具体业务在数据库联机的日常操作，通常对少数记录进行查询、修改。用户较为关心操作的响应时间、数据的安全性、完整性和并发支持的用户数等问题。传统的数据库系统作为数据管理的主要手段，主要用于操作型处理OLTP。 </li>
<li>分析型处理，叫联机分析处理 OLAP（On-Line Analytical Processing），一般针对某些主题的历史数据进行分析，支持管理决策。</li>
<li>首先要明白，数据仓库的出现，并不是要取代数据库。<ul>
<li>数据库是面向事务的设计，数据仓库是面向主题设计的。</li>
<li>数据库一般存储业务数据，数据仓库存储的一般是历史数据。</li>
<li><strong>数据库</strong>设计是尽量避免冗余，一般针对某一业务应用进行设计；比如一张简单的User表，记录用户名、密码等简单数据即可，符合业务应用，但是不符合分析；<strong>数据仓库</strong>在设计是有意引入冗余，依照分析需求，分析维度、分析指标进行设计。</li>
<li>数据库是为捕获数据而设计，数据仓库是为分析数据而设计。<ul>
<li>以银行业务为例。数据库是事务系统的数据平台，客户在银行做的每笔交易都会写入数据库，被记录下来，这里，可以简单地理解为用数据库记账。数据仓库是分析系统的数据平台，它从事务系统获取数据，并做汇总、加工，为决策者提供决策的依据。比如，某银行某分行一个月发生多少交易，该分行当前存款余额是多少。如果存款又多，消费交易又多，那么该地区就有必要设立ATM了。 </li>
<li>显然，银行的交易量是巨大的，通常以百万甚至千万次来计算。事务系统是实时的，这就要求时效性，客户存一笔钱需要几十秒是无法忍受的，这就要求数据库只能存储很短一段时间的数据。而分析系统是事后的，它要提供<strong>关注时间段内</strong>所有的有效数据。这些数据是海量的，汇总计算起来也要慢一些，但是，只要能够提供有效的分析数据就达到目的了。 </li>
</ul>
</li>
<li>数据仓库，是在数据库已经大量存在的情况下，为了进一步挖掘数据资源、为了决策需要而产生的，它决不是所谓的“大型数据库”。</li>
</ul>
</li>
</ul>
<h4 id="1-4-数据仓库分层架构"><a href="#1-4-数据仓库分层架构" class="headerlink" title="1.4 数据仓库分层架构"></a>1.4 数据仓库分层架构</h4><ul>
<li>按照数据流入流出的过程，数据仓库架构可分为三层——<strong>源数据层</strong>、<strong>数据仓库层</strong>、<strong>数据应用层。</strong>                            </li>
<li>数据仓库的数据来源于不同的源数据，并提供多样的数据应用，数据自下而上流入数据仓库后向上层开放应用，而数据仓库只是中间集成化数据管理的一个平台。</li>
<li>源数据层（ODS）：贴源层，此层数据无任何更改，直接沿用外围系统数据结构和数据，不对外开放；为临时存储层，是接口数据的临时存储区域，为后一步的数据处理做准备。</li>
<li>数据仓库层（DW）：也称为细节层，DW层的数据应该是一致的、准确的、干净的数据，即对源系统数据进行了清洗（去除了杂质）后的数据。</li>
<li>数据应用层（DA或APP）：数据展示层， 前端应用直接读取的数据源；根据报表、专题分析需求而计算生成的数据。</li>
<li>数据仓库从各数据源获取数据及在数据仓库内的数据转换和流动都可以认为是ETL（抽取Extra, 转化Transfer, 装载Load）的过程，ETL是数据仓库的流水线，也可以认为是数据仓库的血液，它维系着数据仓库中数据的新陈代谢，而数据仓库日常的管理和维护工作的大部分精力就是保持ETL的正常和稳定。</li>
<li>为什么要对数据仓库分层？<ul>
<li>用空间换时间，通过大量的预处理来提升应用系统的用户体验（效率），因此数据仓库会存在大量冗余的数据；不分层的话，如果源业务系统的业务规则发生变化将会影响整个数据清洗过程，工作量巨大。</li>
<li>通过数据分层管理可以简化数据清洗的过程，因为把原来一步的工作分到了多个步骤去完成，相当于把一个复杂的工作拆成了多个简单的工作，把一个大的黑盒变成了一个白盒，每一层的处理逻辑都相对简单和容易理解，这样我们比较容易保证每一个步骤的正确性，当数据发生错误的时候，往往我们只需要局部调整某个步骤即可。</li>
</ul>
</li>
</ul>
<p>建表的时候为了防止数据中有和分隔符相同的内容，常使用 非打印字符 \001作为分隔符</p>
<h3 id="2-Hive"><a href="#2-Hive" class="headerlink" title="2. Hive"></a>2. Hive</h3><h4 id="2-1-Hive的概念"><a href="#2-1-Hive的概念" class="headerlink" title="2.1 Hive的概念"></a>2.1 Hive的概念</h4><ul>
<li>Hive是基于Hadoop的一个数据仓库工具<ul>
<li>可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。</li>
<li>其本质是将SQL转换为MapReduce的任务进行运算，底层由HDFS来提供数据的存储支持，说白了hive可以理解为一个将SQL转换为MapReduce任务的工具，甚至更进一步可以说hive就是一个MapReduce的客户端</li>
</ul>
</li>
</ul>
<p><img src="/2020/02/17/Hive原理与优化/Snipaste_2019-07-10_23-23-31.png" alt></p>
<p><img src="/2020/02/17/Hive原理与优化/1581912499438.png" alt="1581912499438"></p>
<h4 id="2-2-Hive与数据库的区别"><a href="#2-2-Hive与数据库的区别" class="headerlink" title="2.2 Hive与数据库的区别"></a>2.2 Hive与数据库的区别</h4><p><img src="/2020/02/17/Hive原理与优化/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AC%AC%E5%9B%9B%E6%9C%9F/8_Hive%E4%B8%8EHBase%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E6%88%98/1213_hive%E8%AF%BE%E5%89%8D%E9%A2%84%E4%B9%A0%E8%AF%BE%E4%BB%B6/assets/2018040319335283.png" alt></p>
<ul>
<li>Hive 具有 SQL 数据库的外表，但应用场景完全不同。</li>
<li>Hive 只适合用来做海量离线数据统计分析，也就是数据仓库。</li>
</ul>
<h4 id="2-3-Hive的优缺点"><a href="#2-3-Hive的优缺点" class="headerlink" title="2.3 Hive的优缺点"></a>2.3 Hive的优缺点</h4><ul>
<li>优点<ul>
<li><strong>操作接口采用类SQL语法</strong>，提供快速开发的能力（简单、容易上手）。</li>
<li><strong>避免了去写MapReduce</strong>，减少开发人员的学习成本。</li>
<li><strong>Hive支持用户自定义函数</strong>，用户可以根据自己的需求来实现自己的函数。</li>
</ul>
</li>
<li>缺点<ul>
<li><strong>Hive 的查询延迟很严重</strong><ul>
<li>hadoop jar  xxxx.jar  xxx.class /input /output</li>
<li>进行任务的划分，然后进行计算资源的申请</li>
<li>map 0%  reduce 0%</li>
<li>map 10%  reduce 0%</li>
</ul>
</li>
<li><strong>Hive 不支持事务</strong></li>
</ul>
</li>
</ul>
<h4 id="2-4-Hive架构原理"><a href="#2-4-Hive架构原理" class="headerlink" title="2.4 Hive架构原理"></a>2.4 Hive架构原理</h4><p><img src="/2020/02/17/Hive原理与优化/2019-07-11_11-08-35.png" alt></p>
<ul>
<li>1、用户接口：Client<ul>
<li>CLI（hive shell）</li>
<li>JDBC/ODBC(java访问hive)</li>
<li>WEBUI（浏览器访问hive）</li>
</ul>
</li>
<li>2、元数据：Metastore</li>
<li>元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；<ul>
<li>默认存储在自带的derby数据库中，推荐使用MySQL存储Metastore★</li>
</ul>
</li>
<li>3、Hadoop集群<ul>
<li>使用HDFS进行存储，使用MapReduce进行计算。</li>
</ul>
</li>
<li>4、Driver：驱动器<ul>
<li>解析器（SQL Parser） <ul>
<li>将SQL字符串转换成抽象语法树AST</li>
<li>对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误</li>
</ul>
</li>
<li>编译器（Physical Plan）：将AST编译生成逻辑执行计划</li>
<li>优化器（Query Optimizer）：对逻辑执行计划进行优化，优化是有限的，需要人工进行hive调优</li>
<li>执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说默认就是mapreduce任务</li>
</ul>
</li>
</ul>
<p><img src="/2020/02/17/Hive原理与优化/hive1.png" alt></p>
<h3 id="3-Hive的交互方式"><a href="#3-Hive的交互方式" class="headerlink" title="3. Hive的交互方式"></a>3. Hive的交互方式</h3><ul>
<li>Hive的交互方式主要有三种</li>
<li>使用Hive之前：<ul>
<li>先启动hadoop集群：因为hql语句会被编译成MR任务提交到集群运行；hive表数据一般存储在HDFS上</li>
<li>mysql服务：因为对hive操作过程中，需要访问mysql中存储元数据的库及表</li>
</ul>
</li>
</ul>
<h4 id="3-1-Hive交互shell"><a href="#3-1-Hive交互shell" class="headerlink" title="3.1 Hive交互shell"></a>3.1 Hive交互shell</h4><ul>
<li>在任意路径运行hive</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node03 ~]$ hive</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/17/Hive原理与优化/Image201912101741.png" alt></p>
<h4 id="3-2-Hive-JDBC服务"><a href="#3-2-Hive-JDBC服务" class="headerlink" title="3.2 Hive JDBC服务"></a>3.2 Hive JDBC服务</h4><ul>
<li>启动hiveserver2服务，前台启动与后台启动方式二选一</li>
<li>前台启动</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node03 ~]$ hive --service hiveserver2</span><br></pre></td></tr></table></figure>

<ul>
<li>后台启动</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node03 ~]$ nohup hive --service hiveserver2 &amp;</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/17/Hive原理与优化/Image201912101745.png" alt></p>
<ul>
<li><p>beeline连接hiveserver2服务</p>
<p>若是前台启动hiveserver2，请再开启一个新会话窗口，然后使用beeline连接hive</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node03 ~]$ beeline</span><br><span class="line">beeline&gt; !connect jdbc:hive2://node03:10000</span><br></pre></td></tr></table></figure>

<pre><code>用户名hadoop，密码为空即可</code></pre><p><img src="/2020/02/17/Hive原理与优化/Image201912101749.png" alt></p>
<ul>
<li>帮助信息</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://node03:10000&gt; help</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/17/Hive原理与优化/Image201912101754.png" alt></p>
<ul>
<li>退出</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://node03:10000&gt; !quit</span><br></pre></td></tr></table></figure>

<h4 id="3-3-Hive的命令"><a href="#3-3-Hive的命令" class="headerlink" title="3.3  Hive的命令"></a>3.3  Hive的命令</h4><ul>
<li>hive  -e hql语句<ul>
<li>使用 –e 参数来直接执行hql语句</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node03 ~]$ hive -e "show databases"</span><br></pre></td></tr></table></figure>

<ul>
<li><p>hive  -f  sql文件</p>
<p>使用 –f参数执行包含hql语句的文件</p>
<p>node03执行以下命令准备hive执行脚本</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node03 ~]$ cd /install/</span><br><span class="line">[hadoop@node03 install]$ vim hive.sql</span><br></pre></td></tr></table></figure>

<p>​    文件内容如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create database if not exists myhive;</span><br></pre></td></tr></table></figure>

<p>​    通过以下命令来执行我们的hive脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node03 install]$ hive -f /install/hive.sql</span><br></pre></td></tr></table></figure>

<p>​    查看效果，成功执行hql语句，创建myhive数据库</p>
<p><img src="/2020/02/17/Hive原理与优化/Image201912101938.png" alt></p>
<h3 id="4-Hive的数据类型"><a href="#4-Hive的数据类型" class="headerlink" title="4. Hive的数据类型"></a>4. Hive的数据类型</h3><h4 id="4-1-基本数据类型"><a href="#4-1-基本数据类型" class="headerlink" title="4.1 基本数据类型"></a>4.1 基本数据类型</h4><table>
<thead>
<tr>
<th align="center">类型名称</th>
<th align="center">描述</th>
<th align="center">举例</th>
</tr>
</thead>
<tbody><tr>
<td align="center">boolean</td>
<td align="center">true/false</td>
<td align="center">true</td>
</tr>
<tr>
<td align="center">tinyint</td>
<td align="center">1字节的有符号整数</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">smallint</td>
<td align="center">2字节的有符号整数</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center"><strong>int</strong></td>
<td align="center">4字节的有符号整数</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center"><strong>bigint</strong></td>
<td align="center">8字节的有符号整数</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">float</td>
<td align="center">4字节单精度浮点数</td>
<td align="center">1.0</td>
</tr>
<tr>
<td align="center"><strong>double</strong></td>
<td align="center">8字节单精度浮点数</td>
<td align="center">1.0</td>
</tr>
<tr>
<td align="center"><strong>string</strong></td>
<td align="center">字符串(不设长度)</td>
<td align="center">“abc”</td>
</tr>
<tr>
<td align="center">varchar</td>
<td align="center">字符串（1-65355长度，超长截断）</td>
<td align="center">“abc”</td>
</tr>
<tr>
<td align="center">timestamp</td>
<td align="center">时间戳</td>
<td align="center">1563157873</td>
</tr>
<tr>
<td align="center">date</td>
<td align="center">日期</td>
<td align="center">20190715</td>
</tr>
</tbody></table>
<h4 id="4-2-复合数据类型"><a href="#4-2-复合数据类型" class="headerlink" title="4.2 复合数据类型"></a>4.2 复合数据类型</h4><table>
<thead>
<tr>
<th align="center">类型名称</th>
<th align="center">描述</th>
<th align="center">举例</th>
</tr>
</thead>
<tbody><tr>
<td align="center">array</td>
<td align="center">一组有序的字段，字段类型必须相同 array(元素1，元素2)</td>
<td align="center">Array（1,2,3）</td>
</tr>
<tr>
<td align="center">map</td>
<td align="center">一组无序的键值对 map(k1,v1,k2,v2)</td>
<td align="center">Map(‘a’,1,’b’,2)</td>
</tr>
<tr>
<td align="center">struct</td>
<td align="center">一组命名的字段，字段类型可以不同 struct(元素1，元素2)</td>
<td align="center">Struct(‘a’,1,2,0)</td>
</tr>
</tbody></table>
<ul>
<li>array类型的字段的元素访问方式<ul>
<li>通过下标获取元素，下标从0开始</li>
<li>如获取第一个元素<ul>
<li>array[0]</li>
</ul>
</li>
</ul>
</li>
<li>map类型字段的元素访问方式<ul>
<li>通过键获取值</li>
<li>如获取a这个key对应的value<ul>
<li>map[‘a’]</li>
</ul>
</li>
</ul>
</li>
<li>struct类型字段的元素获取方式<ul>
<li>定义一个字段c的类型为struct{a int, b string}</li>
<li>获取a和b的值<ul>
<li>使用c.a 和c.b 获取其中的元素值</li>
</ul>
</li>
<li>这里可以把这种类型看成是一个对象</li>
</ul>
</li>
<li>示例：创建一张表，包含了array、map、struct类型的字段</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> complex(</span><br><span class="line">         col1 <span class="built_in">array</span>&lt;<span class="built_in">int</span>&gt;,</span><br><span class="line">         col2 <span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="built_in">int</span>&gt;,</span><br><span class="line">         col3 <span class="keyword">struct</span>&lt;a:<span class="keyword">string</span>,b:<span class="built_in">int</span>,c:<span class="keyword">double</span>&gt;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="4-3-hive的复合类型使用说明和实战"><a href="#4-3-hive的复合类型使用说明和实战" class="headerlink" title="4.3 hive的复合类型使用说明和实战"></a>4.3 hive的复合类型使用说明和实战</h4><h5 id="4-3-1-参数说明"><a href="#4-3-1-参数说明" class="headerlink" title="4.3.1 参数说明"></a>4.3.1 参数说明</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">创建表的时候可以指定每行数据的格式,如果使用的是复合数据类型，还需要指定复合数据类型中的元素分割符</span><br><span class="line">ROW FORMAT DELIMITED </span><br><span class="line">	[FIELDS TERMINATED BY char [ESCAPED BY char]] </span><br><span class="line">	[COLLECTION ITEMS TERMINATED BY char]</span><br><span class="line">	[MAP KEYS TERMINATED BY char] </span><br><span class="line">	[LINES TERMINATED BY char]</span><br><span class="line">		</span><br><span class="line">其中这里 </span><br><span class="line">FIELDS TERMINATED BY char 	         指定每一行记录中字段的分割符</span><br><span class="line">COLLECTION ITEMS TERMINATED BY char  指定复合类型中多元素的分割符</span><br><span class="line">MAP KEYS TERMINATED BY char         指定map集合类型中每一个key/value之间的分隔符</span><br><span class="line">LINES TERMINATED BY char            指定每行记录的换行符，一般有默认 就是\n</span><br></pre></td></tr></table></figure>

<h5 id="4-3-2-Array类型"><a href="#4-3-2-Array类型" class="headerlink" title="4.3.2 Array类型"></a>4.3.2 Array类型</h5><ul>
<li><p>array中的数据为相同类型，例如，假如array A中元素[‘a’,’b’,’c’]，则A[1]的值为’b’</p>
</li>
<li><p>准备数据文件</p>
<ul>
<li>t_array.txt  (字段空格分割)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 zhangsan beijing,shanghai</span><br><span class="line">2 lisi shanghai,tianjin</span><br></pre></td></tr></table></figure>
</li>
<li><p>建表语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_array(</span><br><span class="line"><span class="keyword">id</span> <span class="keyword">string</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">string</span>,</span><br><span class="line">locations <span class="built_in">array</span>&lt;<span class="keyword">string</span>&gt;</span><br><span class="line">) <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">' '</span> collection items <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>加载数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/home/hadoop/t_array.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> t_array;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>,<span class="keyword">name</span>,locations[<span class="number">0</span>],locations[<span class="number">1</span>] <span class="keyword">from</span> t_array;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="4-3-3-Map类型"><a href="#4-3-3-Map类型" class="headerlink" title="4.3.3 Map类型"></a>4.3.3 Map类型</h5><ul>
<li><p>map类型中存储key/value类型的数据，后期可以通过[“指定key名称”]访问</p>
</li>
<li><p>准备数据文件</p>
<ul>
<li><p>t_map.txt  (字段空格分割)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 name:zhangsan#age:30</span><br><span class="line">2 name:lisi#age:40</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>建表语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_map(</span><br><span class="line"><span class="keyword">id</span> <span class="keyword">string</span>,</span><br><span class="line">info <span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="keyword">string</span>&gt;</span><br><span class="line">) <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">' '</span> collection items <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'#'</span> <span class="keyword">map</span> <span class="keyword">keys</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">':'</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>加载数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/home/hadoop/t_map.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> t_map;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, info[<span class="string">'name'</span>], info[<span class="string">'age'</span>] <span class="keyword">from</span> t_map;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="4-3-4-Struct类型"><a href="#4-3-4-Struct类型" class="headerlink" title="4.3.4 Struct类型"></a>4.3.4 Struct类型</h5><ul>
<li><p>可以存储不同类型的数据</p>
<ul>
<li>例如c的类型为struct{a INT; b INT}，我们可以通过c.a来访问域a</li>
</ul>
</li>
<li><p>准备数据文件</p>
<ul>
<li><p>t_struct.txt  (字段空格分割)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 zhangsan:30:beijing</span><br><span class="line">2 lisi:40:shanghai</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>建表语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_struct(</span><br><span class="line"><span class="keyword">id</span> <span class="keyword">string</span>,</span><br><span class="line">info <span class="keyword">struct</span>&lt;<span class="keyword">name</span>:<span class="keyword">string</span>, age:<span class="built_in">int</span>,address:<span class="keyword">String</span>&gt;</span><br><span class="line">) <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">' '</span> collection items <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">':'</span> ;</span><br></pre></td></tr></table></figure>
</li>
<li><p>加载数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/home/hadoop/t_struct.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> t_struct;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>,info.name,info.age,info.address <span class="keyword">from</span> t_struct;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="5-Hive的DDL操作"><a href="#5-Hive的DDL操作" class="headerlink" title="5. Hive的DDL操作"></a>5. Hive的DDL操作</h3><h4 id="5-1-数据库DDL操作"><a href="#5-1-数据库DDL操作" class="headerlink" title="5.1 数据库DDL操作"></a>5.1 数据库DDL操作</h4><h5 id="5-1-1-创建数据库"><a href="#5-1-1-创建数据库" class="headerlink" title="5.1.1 创建数据库"></a>5.1.1 创建数据库</h5><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive &gt; create database db_hive;</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">hive &gt; create database if not exists db_hive;</span><br></pre></td></tr></table></figure>

<ul>
<li>数据库在HDFS上的默认存储路径是/user/hive/warehouse/数据库名.db</li>
</ul>
<h5 id="5-1-2-显示所有数据库"><a href="#5-1-2-显示所有数据库" class="headerlink" title="5.1.2 显示所有数据库"></a>5.1.2 显示所有数据库</h5><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br></pre></td></tr></table></figure>

<h5 id="5-1-3-查询数据库"><a href="#5-1-3-查询数据库" class="headerlink" title="5.1.3 查询数据库"></a>5.1.3 查询数据库</h5><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases like 'db_hive*';</span><br></pre></td></tr></table></figure>

<h5 id="5-1-4-查看数据库详情"><a href="#5-1-4-查看数据库详情" class="headerlink" title="5.1.4 查看数据库详情"></a>5.1.4 查看数据库详情</h5><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc database db_hive;</span><br></pre></td></tr></table></figure>

<ul>
<li>显示数据库详细信息</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc database extended db_hive;</span><br></pre></td></tr></table></figure>

<h5 id="5-1-5-切换当前数据库"><a href="#5-1-5-切换当前数据库" class="headerlink" title="5.1.5 切换当前数据库"></a>5.1.5 切换当前数据库</h5><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive &gt; use db_hive;</span><br></pre></td></tr></table></figure>

<h5 id="5-1-6-删除数据库"><a href="#5-1-6-删除数据库" class="headerlink" title="5.1.6 删除数据库"></a>5.1.6 删除数据库</h5><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#删除为空的数据库</span></span><br><span class="line">hive&gt; drop database db_hive;</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果删除的数据库不存在，最好采用if exists 判断数据库是否存在</span></span><br><span class="line">hive&gt; drop database if exists db_hive;</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果数据库中有表存在，这里需要使用cascade强制删除数据库</span></span><br><span class="line">hive&gt; drop database if exists db_hive cascade;</span><br></pre></td></tr></table></figure>

<h4 id="5-2-表DDL操作"><a href="#5-2-表DDL操作" class="headerlink" title="5.2 表DDL操作"></a>5.2 表DDL操作</h4><h5 id="5-2-1-建表语法介绍"><a href="#5-2-1-建表语法介绍" class="headerlink" title="5.2.1 建表语法介绍"></a>5.2.1 建表语法介绍</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] table_name </span><br><span class="line">[(col_name data_type [<span class="keyword">COMMENT</span> col_comment], ...)] </span><br><span class="line">[<span class="keyword">COMMENT</span> table_comment] </span><br><span class="line">[PARTITIONED <span class="keyword">BY</span> (col_name data_type [<span class="keyword">COMMENT</span> col_comment], ...)] 分区</span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...) 分桶</span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span>|<span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS] </span><br><span class="line">[<span class="keyword">ROW</span> <span class="keyword">FORMAT</span> row_format]  <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> “分隔符”</span><br><span class="line">[<span class="keyword">STORED</span> <span class="keyword">AS</span> file_format] </span><br><span class="line">[LOCATION hdfs_path]</span><br></pre></td></tr></table></figure>

<p>官网地址：<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL</a></p>
<ul>
<li>字段解释说明<ul>
<li>create table    创建一个指定名字的表</li>
<li>EXTERNAL       创建一个外部表，在建表的同时指定一个指向实际数据的路径（LOCATION），指定表的数据保存在哪里</li>
<li>COMMENT       为表和列添加注释</li>
<li>PARTITIONED BY    创建分区表</li>
<li>CLUSTERED BY    创建分桶表</li>
<li>SORTED BY    按照字段排序（一般不常用）</li>
<li>ROW FORMAT    指定每一行中字段的分隔符<ul>
<li>row format delimited fields terminated by ‘\t’</li>
</ul>
</li>
<li>STORED AS    指定存储文件类型<ul>
<li>常用的存储文件类型：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、ORCFILE（列式存储格式文件）</li>
<li>如果文件数据是纯文本，可以使用STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE</li>
</ul>
</li>
<li>LOCATION    指定表在HDFS上的存储位置。</li>
</ul>
</li>
</ul>
<h5 id="5-2-2-创建内部表"><a href="#5-2-2-创建内部表" class="headerlink" title="5.2.2 创建内部表"></a>5.2.2 创建内部表</h5><ul>
<li>1、使用标准的建表语句直接建表</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> myhive;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> stu(<span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">name</span> <span class="keyword">string</span>);</span><br><span class="line"></span><br><span class="line">可以通过<span class="keyword">insert</span> <span class="keyword">into</span>向hive表当中插入数据，但是不建议工作当中这么做；因为每个<span class="keyword">insert</span>语句转换成mr后会生成一个文件</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> stu(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">"zhangsan"</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> stu(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span>(<span class="number">2</span>,<span class="string">"lisi"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span>  stu;</span><br></pre></td></tr></table></figure>

<ul>
<li>2、查询建表法<ul>
<li>通过AS 查询语句完成建表：将子查询的结果存入新表里</li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> myhive.stu1 <span class="keyword">as</span> <span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">name</span> <span class="keyword">from</span> stu;</span><br><span class="line"></span><br><span class="line">表中有数据</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> stu1;</span><br></pre></td></tr></table></figure>

<ul>
<li>3、like建表法<ul>
<li>根据已经存在的表结构创建表</li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> myhive.stu2 <span class="keyword">like</span> stu;</span><br><span class="line"></span><br><span class="line">表中没有数据</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> stu2;</span><br></pre></td></tr></table></figure>

<ul>
<li>4、查询表的类型</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive &gt; desc formatted myhive.stu;</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/17/Hive原理与优化/2019-07-12_14-33-00.png" alt></p>
<ul>
<li>hql示例：创建内部表并指定字段之间的分隔符，指定文件的存储格式，以及数据存放的位置</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> myhive.stu3(<span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">name</span> <span class="keyword">string</span>)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span> <span class="keyword">stored</span> <span class="keyword">as</span> textfile </span><br><span class="line">location <span class="string">'/user/stu3'</span>;</span><br></pre></td></tr></table></figure>

<h5 id="5-2-3-创建外部表"><a href="#5-2-3-创建外部表" class="headerlink" title="5.2.3 创建外部表"></a>5.2.3 创建外部表</h5><ul>
<li>外部表因为是指定其他的hdfs路径的数据加载到表当中来</li>
<li>所以hive表会认为自己不完全独占这份数据，所以删除hive表的时候，数据仍然存放在hdfs当中，不会删掉</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> myhive.teacher (t_id <span class="keyword">string</span>, t_name <span class="keyword">string</span>) <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>创建外部表的时候需要加上<strong>external</strong> 关键字</li>
<li>location字段可以指定，也可以不指定<ul>
<li>指定就是数据存放的具体目录</li>
<li>不指定就是使用默认目录 /user/hive/warehouse</li>
</ul>
</li>
</ul>
<p><img src="/2020/02/17/Hive原理与优化/2019-07-12_14-51-53.png" alt></p>
<ul>
<li><p>向外部表当中加载数据：</p>
<ul>
<li>我们前面已经看到过通过insert的方式向内部表当中插入数据，外部表也可以通过insert的方式进行插入数据，只不过insert的方式，我们一般都不推荐</li>
<li>实际工作当中我们都是使用load的方式来加载数据到内部表或者外部表</li>
</ul>
</li>
<li><p>load数据可以从本地文件系统加载或者也可以从hdfs上面的数据进行加载</p>
<ul>
<li>从本地文件系统加载数据到teacher表当中去，将我们附件当汇总的数据资料都上传到node03服务器的/kkb/install/hivedatas路径下面去</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /kkb/install/hivedatas</span><br></pre></td></tr></table></figure>

<ul>
<li>将数据都上传到/kkb/install/hivedatas路径下</li>
<li>然后在hive客户端下执行以下操作</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath '/kkb/install/hivedatas/teacher.csv' into table myhive.teacher;</span><br></pre></td></tr></table></figure>
</li>
<li><p>从hdfs上面加载文件到teacher表里面去(将teacher.csv文件上传到hdfs的/kkb/hdfsload/hivedatas路径下)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /kkb/install/hivedatas</span><br><span class="line">hdfs dfs -mkdir -p /kkb/hdfsload/hivedatas</span><br><span class="line">hdfs dfs -put teacher.csv /kkb/hdfsload/hivedatas</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在hive的客户端当中执行</span></span><br><span class="line">load data inpath '/kkb/hdfsload/hivedatas' overwrite into table myhive.teacher;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="5-2-4-内部表与外部表的互相转换"><a href="#5-2-4-内部表与外部表的互相转换" class="headerlink" title="5.2.4 内部表与外部表的互相转换"></a>5.2.4 内部表与外部表的互相转换</h5><ul>
<li>1、内部表转换为外部表</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将stu内部表改为外部表</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> stu <span class="keyword">set</span> tblproperties(<span class="string">'EXTERNAL'</span>=<span class="string">'TRUE'</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li>2、外部表转换为内部表</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把teacher外部表改为内部表</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> teacher <span class="keyword">set</span> tblproperties(<span class="string">'EXTERNAL'</span>=<span class="string">'FALSE'</span>);</span><br></pre></td></tr></table></figure>

<h5 id="5-2-5-内部表与外部表的区别"><a href="#5-2-5-内部表与外部表的区别" class="headerlink" title="5.2.5 内部表与外部表的区别"></a>5.2.5 内部表与外部表的区别</h5><ul>
<li>1、建表语法的区别<ul>
<li>外部表在创建的时候需要加上external关键字</li>
</ul>
</li>
<li>2、删除表之后的区别<ul>
<li>内部表删除后，表的元数据和真实数据都被删除了</li>
<li>外部表删除后，仅仅只是把该表的元数据删除了，真实数据还在，后期还是可以恢复出来</li>
</ul>
</li>
</ul>
<h5 id="5-2-6-内部表与外部表的使用时机"><a href="#5-2-6-内部表与外部表的使用时机" class="headerlink" title="5.2.6 内部表与外部表的使用时机"></a>5.2.6 内部表与外部表的使用时机</h5><ul>
<li>内部表由于删除表的时候会同步删除HDFS的数据文件，所以确定如果一个表仅仅是你独占使用，其他人不使用的时候就可以创建内部表，如果一个表的文件数据，其他人也要使用，那么就创建外部表</li>
<li>一般外部表都是用在数据仓库的ODS层</li>
<li>内部表都是用在数据仓库的DW层</li>
</ul>
<h5 id="5-2-7-hive的分区表"><a href="#5-2-7-hive的分区表" class="headerlink" title="5.2.7 hive的分区表"></a>5.2.7 hive的分区表</h5><ul>
<li>如果hive当中所有的数据都存入到一个文件夹下面，那么在使用MR计算程序的时候，读取一整个目录下面的所有文件来进行计算，就会变得特别慢，因为数据量太大了</li>
<li>实际工作当中一般都是计算前一天的数据，所以我们只需要将前一天的数据挑出来放到一个文件夹下面即可，专门去计算前一天的数据。这样就可以使用hive当中的分区表，通过分文件夹的形式，将每一天的数据都分成为一个文件夹，然后我们计算数据的时候，通过指定前一天的文件夹即可只计算前一天的数据。</li>
<li>在大数据中，最常用的一种思想就是分治，我们可以把大的文件切割划分成一个个的小的文件，这样每次操作一个小的文件就会很容易了，同样的道理，在hive当中也是支持这种思想的，就是我们可以把大的数据，按照每天，或者每小时进行切分成一个个的小的文件，这样去操作小的文件就会容易得多了</li>
</ul>
<p><img src="/2020/02/17/Hive原理与优化/2019-07-15_11-35-37.png" alt></p>
<ul>
<li>在文件系统上建立文件夹，把表的数据放在不同文件夹下面，加快查询速度。</li>
<li>创建分区表语法</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (myhive)&gt; create table score(s_id string, c_id string, s_score int) partitioned by (month string) row format delimited fields terminated by '\t';</span><br></pre></td></tr></table></figure>

<ul>
<li>创建一个表带多个分区</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (myhive)&gt; create table score2 (s_id string,c_id string, s_score int) partitioned by (year string, month string, day string) row format delimited fields terminated by '\t';</span><br></pre></td></tr></table></figure>

<ul>
<li>加载数据到分区表当中去</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (myhive)&gt;load data local inpath '/kkb/install/hivedatas/score.csv' into table score partition (month='201806');</span><br></pre></td></tr></table></figure>

<ul>
<li>加载数据到多分区表当中去</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (myhive)&gt; load data local inpath '/kkb/install/hivedatas/score.csv' into table score2 partition(year='2018', month='06', day='01');</span><br></pre></td></tr></table></figure>

<ul>
<li>查看分区</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (myhive)&gt; show  partitions  score;</span><br></pre></td></tr></table></figure>

<ul>
<li>添加一个分区</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (myhive)&gt; alter table score add partition(month=&apos;201805&apos;);</span><br></pre></td></tr></table></figure>

<ul>
<li>同时添加多个分区</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (myhive)&gt; alter table score add partition(month='201804') partition(month = '201803');</span><br></pre></td></tr></table></figure>

<ul>
<li>注意：添加分区之后就可以在hdfs文件系统当中看到表下面多了一个文件夹</li>
<li>删除分区</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (myhive)&gt; alter table score drop partition(month = '201806');</span><br></pre></td></tr></table></figure>

<ul>
<li><p>外部分区表综合练习：</p>
</li>
<li><p>需求描述：</p>
<ul>
<li>现在有一个文件score.csv文件，里面有三个字段，分别是s_id string, c_id string, s_score int</li>
<li>字段都是使用 \t进行分割</li>
<li>存放在集群的这个目录下/scoredatas/day=20180607，这个文件每天都会生成，存放到对应的日期文件夹下面去</li>
<li>文件别人也需要公用，不能移动</li>
<li>请创建hive对应的表，并将数据加载到表中，进行数据统计分析，且删除表之后，数据不能删除</li>
</ul>
</li>
<li><p>需求实现:</p>
</li>
<li><p>数据准备:</p>
</li>
<li><p>node03执行以下命令，将数据上传到hdfs上面去</p>
<p>将我们的score.csv上传到node03服务器的/kkb/install/hivedatas目录下，然后将score.csv文件上传到HDFS的/scoredatas/day=20180607目录上</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /kkb/install/hivedatas/</span><br><span class="line">hdfs dfs -mkdir -p /scoredatas/day=20180607</span><br><span class="line">hdfs dfs -put score.csv /scoredatas/day=20180607/</span><br></pre></td></tr></table></figure>

<ul>
<li>创建外部分区表，并指定文件数据存放目录</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (myhive)&gt; create external table score4(s_id string, c_id string, s_score int) partitioned by (day string) row format delimited fields terminated by '\t' location '/scoredatas';</span><br></pre></td></tr></table></figure>

<ul>
<li>进行表的修复，说白了就是建立我们表与我们数据文件之间的一个关系映射()</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (myhive)&gt; msck repair table score4;</span><br></pre></td></tr></table></figure>

<ul>
<li>修复成功之后即可看到数据已经全部加载到表当中去了</li>
</ul>
<h5 id="5-2-8-hive修改表结构"><a href="#5-2-8-hive修改表结构" class="headerlink" title="5.2.8 hive修改表结构"></a>5.2.8 hive修改表结构</h5><ul>
<li>修改表的名称<ul>
<li>修改表名称语法</li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span>  old_table_name  <span class="keyword">rename</span> <span class="keyword">to</span>  new_table_name;</span><br></pre></td></tr></table></figure>

<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; alter table stu3 rename to stu4;</span><br></pre></td></tr></table></figure>

<ul>
<li>增加/修改/替换列<ul>
<li>查看表结构</li>
</ul>
</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc stu4;</span><br><span class="line">hive&gt; desc formatted stu4;</span><br></pre></td></tr></table></figure>

<ul>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-AlterColumn" target="_blank" rel="noopener">官网文档</a></li>
<li>增加列</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; alter table stu4 add columns(address string);</span><br></pre></td></tr></table></figure>

<ul>
<li>修改列</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; alter table stu4 change column address address_id int;</span><br></pre></td></tr></table></figure>

<h3 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h3><ul>
<li><p>hive cli命令窗口查看本地文件系统</p>
<ul>
<li><p>与操作本地文件系统类似，这里需要使用 ! (感叹号)，并且最后需要加上 ;(分号) </p>
</li>
<li><p>例如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!ls /home;</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/17/Hive原理与优化/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AC%AC%E5%9B%9B%E6%9C%9F/8_Hive%E4%B8%8EHBase%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E6%88%98/1213_hive%E8%AF%BE%E5%89%8D%E9%A2%84%E4%B9%A0%E8%AF%BE%E4%BB%B6/assets/Image201912111127.png" alt></p>
</li>
</ul>
</li>
<li><p>hive cli命令窗口查看HDFS文件系统</p>
<ul>
<li>与查看HDFS文件系统类似</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfs -ls /user;</span><br></pre></td></tr></table></figure>

<p>  <img src="/2020/02/17/Hive原理与优化/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AC%AC%E5%9B%9B%E6%9C%9F/8_Hive%E4%B8%8EHBase%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E6%88%98/1213_hive%E8%AF%BE%E5%89%8D%E9%A2%84%E4%B9%A0%E8%AF%BE%E4%BB%B6/assets/Image201912111128.png" alt></p>
</li>
<li><p>hive的底层执行引擎有3种</p>
<ul>
<li>mapreduce(默认)</li>
<li>tez（支持DAG作业的计算框架）mr1–&gt;mr2 –&gt;mr3</li>
<li>spark（基于内存的分布式计算框架）</li>
</ul>
</li>
</ul>
<ul>
<li>Hive客户端JDBC操作<ul>
<li>启动hiveserver2</li>
<li>node03执行以下命令启动hiveserver2的服务端</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /kkb/install/hive-1.1.0-cdh5.14.2/</span><br><span class="line">nohup bin/hive --service hiveserver2 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>

<ul>
<li>引入依赖</li>
</ul>
<ul>
<li>创建maven工程，引入依赖</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">id</span>&gt;</span>cloudera<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repository.cloudera.com/artifactory/cloudera-repos/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.0-cdh5.14.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.0-cdh5.14.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-cli<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.0-cdh5.14.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.0-cdh5.14.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                 <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                 <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                 <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">                 <span class="comment">&lt;!--    &lt;verbal&gt;true&lt;/verbal&gt;--&gt;</span></span><br><span class="line">             <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>代码开发</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.sql.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HiveJDBC</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String url=<span class="string">"jdbc:hive2://192.168.52.120:10000/myhive"</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Class.forName(<span class="string">"org.apache.hive.jdbc.HiveDriver"</span>);</span><br><span class="line">        <span class="comment">//获取数据库连接</span></span><br><span class="line">        Connection connection = DriverManager.getConnection(url, <span class="string">"hadoop"</span>,<span class="string">""</span>);</span><br><span class="line">        <span class="comment">//定义查询的sql语句</span></span><br><span class="line">        String sql=<span class="string">"select * from stu"</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            PreparedStatement ps = connection.prepareStatement(sql);</span><br><span class="line">            ResultSet rs = ps.executeQuery();</span><br><span class="line">            <span class="keyword">while</span> (rs.next())&#123;</span><br><span class="line">                <span class="comment">//获取id字段值</span></span><br><span class="line">                <span class="keyword">int</span> id = rs.getInt(<span class="number">1</span>);</span><br><span class="line">                <span class="comment">//获取deptid字段</span></span><br><span class="line">                String name = rs.getString(<span class="number">2</span>);</span><br><span class="line">                System.out.println(id+<span class="string">"\t"</span>+name);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="/2020/02/17/Hive原理与优化/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AC%AC%E5%9B%9B%E6%9C%9F/8_Hive%E4%B8%8EHBase%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E6%88%98/1213_hive%E8%AF%BE%E5%89%8D%E9%A2%84%E4%B9%A0%E8%AF%BE%E4%BB%B6/assets/hive%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8.png" alt></p>

    </div>

    
    
    
        
      
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>小鱼儿</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/2020/02/17/Hive原理与优化/" title="Hive原理与优化">http://yoursite.com/2020/02/17/Hive原理与优化/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-Hans" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>
</div>

      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/Hive/" rel="tag"># Hive</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2020/02/16/Spark底层核心之RDD/" rel="next" title="Spark底层核心之RDD">
                  <i class="fa fa-chevron-left"></i> Spark底层核心之RDD
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#0-准备"><span class="nav-number">1.</span> <span class="nav-text">0.准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-数据仓库"><span class="nav-number">2.</span> <span class="nav-text">1. 数据仓库</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-数据仓库的基本概念"><span class="nav-number">2.1.</span> <span class="nav-text">1.1 数据仓库的基本概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-数据仓库的主要特征"><span class="nav-number">2.2.</span> <span class="nav-text">1.2 数据仓库的主要特征</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-数据仓库与数据库区别"><span class="nav-number">2.3.</span> <span class="nav-text">1.3 数据仓库与数据库区别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-4-数据仓库分层架构"><span class="nav-number">2.4.</span> <span class="nav-text">1.4 数据仓库分层架构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Hive"><span class="nav-number">3.</span> <span class="nav-text">2. Hive</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-Hive的概念"><span class="nav-number">3.1.</span> <span class="nav-text">2.1 Hive的概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-Hive与数据库的区别"><span class="nav-number">3.2.</span> <span class="nav-text">2.2 Hive与数据库的区别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-Hive的优缺点"><span class="nav-number">3.3.</span> <span class="nav-text">2.3 Hive的优缺点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-Hive架构原理"><span class="nav-number">3.4.</span> <span class="nav-text">2.4 Hive架构原理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Hive的交互方式"><span class="nav-number">4.</span> <span class="nav-text">3. Hive的交互方式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-Hive交互shell"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 Hive交互shell</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-Hive-JDBC服务"><span class="nav-number">4.2.</span> <span class="nav-text">3.2 Hive JDBC服务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-Hive的命令"><span class="nav-number">4.3.</span> <span class="nav-text">3.3  Hive的命令</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Hive的数据类型"><span class="nav-number">5.</span> <span class="nav-text">4. Hive的数据类型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-基本数据类型"><span class="nav-number">5.1.</span> <span class="nav-text">4.1 基本数据类型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-复合数据类型"><span class="nav-number">5.2.</span> <span class="nav-text">4.2 复合数据类型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-hive的复合类型使用说明和实战"><span class="nav-number">5.3.</span> <span class="nav-text">4.3 hive的复合类型使用说明和实战</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#4-3-1-参数说明"><span class="nav-number">5.3.1.</span> <span class="nav-text">4.3.1 参数说明</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-3-2-Array类型"><span class="nav-number">5.3.2.</span> <span class="nav-text">4.3.2 Array类型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-3-3-Map类型"><span class="nav-number">5.3.3.</span> <span class="nav-text">4.3.3 Map类型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-3-4-Struct类型"><span class="nav-number">5.3.4.</span> <span class="nav-text">4.3.4 Struct类型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-Hive的DDL操作"><span class="nav-number">6.</span> <span class="nav-text">5. Hive的DDL操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-数据库DDL操作"><span class="nav-number">6.1.</span> <span class="nav-text">5.1 数据库DDL操作</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#5-1-1-创建数据库"><span class="nav-number">6.1.1.</span> <span class="nav-text">5.1.1 创建数据库</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-1-2-显示所有数据库"><span class="nav-number">6.1.2.</span> <span class="nav-text">5.1.2 显示所有数据库</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-1-3-查询数据库"><span class="nav-number">6.1.3.</span> <span class="nav-text">5.1.3 查询数据库</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-1-4-查看数据库详情"><span class="nav-number">6.1.4.</span> <span class="nav-text">5.1.4 查看数据库详情</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-1-5-切换当前数据库"><span class="nav-number">6.1.5.</span> <span class="nav-text">5.1.5 切换当前数据库</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-1-6-删除数据库"><span class="nav-number">6.1.6.</span> <span class="nav-text">5.1.6 删除数据库</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-2-表DDL操作"><span class="nav-number">6.2.</span> <span class="nav-text">5.2 表DDL操作</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#5-2-1-建表语法介绍"><span class="nav-number">6.2.1.</span> <span class="nav-text">5.2.1 建表语法介绍</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-2-2-创建内部表"><span class="nav-number">6.2.2.</span> <span class="nav-text">5.2.2 创建内部表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-2-3-创建外部表"><span class="nav-number">6.2.3.</span> <span class="nav-text">5.2.3 创建外部表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-2-4-内部表与外部表的互相转换"><span class="nav-number">6.2.4.</span> <span class="nav-text">5.2.4 内部表与外部表的互相转换</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-2-5-内部表与外部表的区别"><span class="nav-number">6.2.5.</span> <span class="nav-text">5.2.5 内部表与外部表的区别</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-2-6-内部表与外部表的使用时机"><span class="nav-number">6.2.6.</span> <span class="nav-text">5.2.6 内部表与外部表的使用时机</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-2-7-hive的分区表"><span class="nav-number">6.2.7.</span> <span class="nav-text">5.2.7 hive的分区表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-2-8-hive修改表结构"><span class="nav-number">6.2.8.</span> <span class="nav-text">5.2.8 hive修改表结构</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#拓展"><span class="nav-number">7.</span> <span class="nav-text">拓展</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#总结"><span class="nav-number">8.</span> <span class="nav-text">总结</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/fish.png"
      alt="小鱼儿">
  <p class="site-author-name" itemprop="name">小鱼儿</p>
  <div class="site-description" itemprop="description">肩膀有点痒，可能在长小翅膀</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">52</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">43</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    
  
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-Hans" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">小鱼儿</span>
</div>

        












        
      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/pisces.js?v=7.4.1"></script>

<script src="/js/next-boot.js?v=7.4.1"></script>



  





















  

  

  

</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>

